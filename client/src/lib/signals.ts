export interface Signal {
  id: string;
  title: string;
  truth: string;
  definition: string;
}

export const SIGNALS: Signal[] = [
  {
    id: "01",
    title: "PROBLEM GRAVITY",
    truth: "The measurable capability of a specific problem to pull resources, attention, and urgency into its orbit naturally.",
    definition: "Not all problems are created equal. High-gravity problems solve themselves once unblocked; low-gravity problems require constant push."
  },
  {
    id: "02",
    title: "FRICTION INDEX",
    truth: "The drag coefficient of your organizational workflows; where velocity goes to die.",
    definition: "Every handoff, approval, and context switch adds friction. AI's primary value is reducing this coefficient to zero."
  },
  {
    id: "03",
    title: "DECISION DENSITY",
    truth: "The volume of high-stakes choices required per unit of execution time.",
    definition: "AI should lower decision density by automating the trivial, allowing humans to focus solely on the consequential."
  },
  {
    id: "04",
    title: "TRUST SURFACE AREA",
    truth: "The exposure level where human intervention is mandatory to maintain stakeholder confidence.",
    definition: "Automate the backend; curate the frontend. Know exactly where the human must be in the loop."
  },
  {
    id: "05",
    title: "LATENCY SENSITIVITY",
    truth: "The precise cost of delay. In some loops, speed is the only feature that matters.",
    definition: "Real-time intelligence is worth 10x more than retrospective analysis. Shrink the loop."
  },
  {
    id: "06",
    title: "CONTEXT DECAY",
    truth: "The rate at which information becomes irrelevant or toxic as it moves through the organization.",
    definition: "Information rots. AI preserves context fidelity across teams, timezones, and tools."
  },
  {
    id: "07",
    title: "TOOL FRICTION",
    truth: "The cognitive load required to switch between the instruments of work.",
    definition: "The best tool is the one you don't notice. AI should be the glue, not another app."
  },
  {
    id: "08",
    title: "HITL LOAD",
    truth: "The tax paid in human attention to correct, verify, or steer automated systems.",
    definition: "Human-in-the-loop is a feature, not a bug—but only if the human is doing high-value steering, not janitorial cleanup."
  },
  {
    id: "09",
    title: "FAILURE VISIBILITY",
    truth: "How obvious it is when a system breaks. Silent failures are the highest risk.",
    definition: "Loud failures are safe; silent failures are fatal. Build systems that scream when they drift."
  },
  {
    id: "10",
    title: "STATE DRIFT",
    truth: "The divergence between the system’s map of reality and the territory itself.",
    definition: "The map is not the territory. AI must constantly re-calibrate its internal model against ground truth."
  },
  {
    id: "11",
    title: "OUTCOME BINDING",
    truth: "How tightly an AI initiative is coupled to a P&L result versus a vanity metric.",
    definition: "If you can't trace the AI output to a dollar on the P&L, it's a science project, not a business strategy."
  },
  {
    id: "12",
    title: "WORKFLOW INERTIA",
    truth: "The resistance of an existing process to being reshaped by intelligence.",
    definition: "Culture eats strategy; inertia eats innovation. You must break the inertia before you can build the new."
  },
  {
    id: "13",
    title: "KNOWLEDGE HALF-LIFE",
    truth: "The speed at which your proprietary insight becomes a commodity.",
    definition: "What you know today will be embedded in a model tomorrow. Your value is in the synthesis, not the raw data."
  },
  {
    id: "14",
    title: "AGENT OWNERSHIP",
    truth: "Who owns the outcome when the agent acts? The defining legal boundary of the next decade.",
    definition: "Accountability cannot be automated. The human must always own the risk, even if the agent does the work."
  },
  {
    id: "15",
    title: "INTEGRATION DEPTH",
    truth: "Is the AI a wrapper, or is it woven into the substrate of the business logic?",
    definition: "Wrappers are fragile; deep integration is antifragile. Build into the core, not on top of the skin."
  },
  {
    id: "16",
    title: "CAMPGROUND VS FACTORY",
    truth: "Are you building for safety and comfort, or for maximum explosive output?",
    definition: "Campgrounds are for prototypes; factories are for production. Know which mode you are in."
  },
  {
    id: "17",
    title: "SIGNAL-TO-NOISE",
    truth: "The ratio of actionable insight to raw data generated by your systems.",
    definition: "More data is not better; more signal is better. AI is a filter, not a hose."
  },
  {
    id: "18",
    title: "ADOPTION VELOCITY",
    truth: "The time it takes for a new capability to become the default way of working.",
    definition: "If they aren't using it within 10 days, they never will. Velocity is the only metric of adoption."
  },
  {
    id: "19",
    title: "SECOND-BRAIN LEVERAGE",
    truth: "The multiplier effect of offloading memory and synthesis to external substrates.",
    definition: "Your biological brain is for creativity; your digital brain is for scale. Don't mix them up."
  },
  {
    id: "20",
    title: "OUTCOME COMPOUNDING",
    truth: "When one efficiency gain automatically triggers the next, creating a flywheel.",
    definition: "Linear gains are boring; exponential gains are transformative. Look for the compound interest of intelligence."
  }
];

export const INDUSTRIES = [
  "SaaS / Tech",
  "Fintech / Banking",
  "Healthcare / Bio",
  "Retail / E-comm",
  "Manufacturing",
  "Professional Services"
];

export const ROLES = [
  "CEO / Founder",
  "CTO / VP Eng",
  "Product Leader",
  "Operations Lead",
  "Investor / VC"
];
